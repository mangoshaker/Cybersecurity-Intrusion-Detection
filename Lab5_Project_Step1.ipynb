{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7598ae96-1b42-4836-a461-9b9379d45c96",
   "metadata": {},
   "source": [
    "## Descriptive analysis of your data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2818669-e923-4a04-8a50-93e1c0f9c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BASIC INFORMATIONS (intrusion_data.info())\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9537 entries, 0 to 9536\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   session_id           9537 non-null   object \n",
      " 1   network_packet_size  9537 non-null   int64  \n",
      " 2   protocol_type        9537 non-null   object \n",
      " 3   login_attempts       9537 non-null   int64  \n",
      " 4   session_duration     9537 non-null   float64\n",
      " 5   encryption_used      7571 non-null   object \n",
      " 6   ip_reputation_score  9537 non-null   float64\n",
      " 7   failed_logins        9537 non-null   int64  \n",
      " 8   browser_type         9537 non-null   object \n",
      " 9   unusual_time_access  9537 non-null   int64  \n",
      " 10  attack_detected      9537 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 819.7+ KB\n",
      "==================================================\n",
      "\n",
      "DESCRIPTIVES STATISTICS (intrusion_data.describe())\n",
      "\n",
      "       network_packet_size  login_attempts  session_duration  \\\n",
      "count          9537.000000     9537.000000       9537.000000   \n",
      "mean            500.430639        4.032086        792.745312   \n",
      "std             198.379364        1.963012        786.560144   \n",
      "min              64.000000        1.000000          0.500000   \n",
      "25%             365.000000        3.000000        231.953006   \n",
      "50%             499.000000        4.000000        556.277457   \n",
      "75%             635.000000        5.000000       1105.380602   \n",
      "max            1285.000000       13.000000       7190.392213   \n",
      "\n",
      "       ip_reputation_score  failed_logins  unusual_time_access  \\\n",
      "count          9537.000000    9537.000000          9537.000000   \n",
      "mean              0.331338       1.517773             0.149942   \n",
      "std               0.177175       1.033988             0.357034   \n",
      "min               0.002497       0.000000             0.000000   \n",
      "25%               0.191946       1.000000             0.000000   \n",
      "50%               0.314778       1.000000             0.000000   \n",
      "75%               0.453388       2.000000             0.000000   \n",
      "max               0.924299       5.000000             1.000000   \n",
      "\n",
      "       attack_detected  \n",
      "count      9537.000000  \n",
      "mean          0.447101  \n",
      "std           0.497220  \n",
      "min           0.000000  \n",
      "25%           0.000000  \n",
      "50%           0.000000  \n",
      "75%           1.000000  \n",
      "max           1.000000  \n",
      "==================================================\n",
      "\n",
      "DATA OVERVIEW (intrusion_data.head())\n",
      "\n",
      "  session_id  network_packet_size protocol_type  login_attempts  \\\n",
      "0  SID_00001                  599           TCP               4   \n",
      "1  SID_00002                  472           TCP               3   \n",
      "2  SID_00003                  629           TCP               3   \n",
      "3  SID_00004                  804           UDP               4   \n",
      "4  SID_00005                  453           TCP               5   \n",
      "\n",
      "   session_duration encryption_used  ip_reputation_score  failed_logins  \\\n",
      "0        492.983263             DES             0.606818              1   \n",
      "1       1557.996461             DES             0.301569              0   \n",
      "2         75.044262             DES             0.739164              2   \n",
      "3        601.248835             DES             0.123267              0   \n",
      "4        532.540888             AES             0.054874              1   \n",
      "\n",
      "  browser_type  unusual_time_access  attack_detected  \n",
      "0         Edge                    0                1  \n",
      "1      Firefox                    0                0  \n",
      "2       Chrome                    0                1  \n",
      "3      Unknown                    0                1  \n",
      "4      Firefox                    0                0  \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# 1. Load data\n",
    "intrusion_data = pd.read_csv(\"cybersecurity_intrusion_data.csv\", sep=',')\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"BASIC INFORMATIONS (intrusion_data.info())\\n\")\n",
    "intrusion_data.info()\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nDESCRIPTIVES STATISTICS (intrusion_data.describe())\\n\")\n",
    "print(intrusion_data.describe())\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nDATA OVERVIEW (intrusion_data.head())\\n\")\n",
    "print(intrusion_data.head())\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25146645-4c3f-45ca-ba4a-62dd631be50d",
   "metadata": {},
   "source": [
    "- Thanks to this analysis, we can see that the column \"encryption\" has some missing values (1966 precisely)\n",
    "- As we can see the column \"attack_detected\" is a type int64 (with his values being only 0 or 1), so we can conclude that this is a binary classification problem.\n",
    "- The \"session_id\" column is useless for our problem because it is a unique identifier, so we can drop the column later. \n",
    "\n",
    "- Also, the column \"session_duration\" needs some scaling, as we can see a big difference between the max value and the 75% percentile. \n",
    "- Here, we are confronted to a relatively balanced problem, with approximatively 45% of sessions classified as attacks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35f994-5c66-4fbf-aa58-7388e7a612c9",
   "metadata": {},
   "source": [
    "## Implementation of the necessary pre-processing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b0880c5-6d90-4222-b688-bb5c414295ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_Train(X_train): (7629, 9)\n",
      "Size of X_Test(X_test): (1908, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#Dropping the unique identifier column, and putting the column attack_detected as the target variable \n",
    "X = intrusion_data.drop(['attack_detected', 'session_id'], axis=1)\n",
    "y = intrusion_data['attack_detected']\n",
    "\n",
    "#Splitting dataset into training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) \n",
    "\n",
    "print(f\"Size of X_Train(X_train): {X_train.shape}\")\n",
    "print(f\"Size of X_Test(X_test): {X_test.shape}\")\n",
    "\n",
    "#Indentifing column by type\n",
    "numerical_features = X.select_dtypes(include=np.number).columns\n",
    "categorical_features = X.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c43f7226-9b3c-4d40-ba9e-60af5af98a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Transformations : Standardisation (scaling)\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf85986-59f5-4687-8daf-0f39383fc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# On combine les deux pipelines en ciblant les colonnes correspondantes\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7448fcb2-3244-4de2-a852-3fcb75f66461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After pre-processing\n",
      "Taille de X_train_processed: (7629, 16)\n",
      "Taille de X_test_processed: (1908, 16)\n",
      "Nombre total de features après encodage : 16\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# transform\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"\\nAfter pre-processing\")\n",
    "print(f\"Taille de X_train_processed: {X_train_processed.shape}\")\n",
    "print(f\"Taille de X_test_processed: {X_test_processed.shape}\")\n",
    "\n",
    "# Optional: Afficher le nombre de features créées\n",
    "num_new_features = X_train_processed.shape[1]\n",
    "print(f\"Nombre total de features après encodage : {num_new_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd5913-71d4-48d7-a3a9-666f14acf5d3",
   "metadata": {},
   "source": [
    "## Formalisation of the problem ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316043e8-a5f5-4206-9b66-a0cfd4ef5896",
   "metadata": {},
   "source": [
    "The project aims to solve a Binary Classification problem using supervised learning. The main objective is to \n",
    "build a model capable of predicting, for each network session, whether it constitutes an Intrusion/Attack (class 1) or Normal Traffic (class 0). The target variable is the attack_detected column. The predictive variables are all other columns after pre-processing, encoding, and scaling. Model evaluation will primarily focus on Recall and the F1-Score for the 'Attack' class. These metrics are prioritized because the most critical risk in cybersecurity is the False Negative (an undetected attack), and Accuracy alone is insufficient to guarantee system reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2798f32-963e-448b-999f-f58bd02c7c92",
   "metadata": {},
   "source": [
    "## Selection of a baseline model and implementation of the model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca113ee8-7e82-4e45-a606-dc17d716b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "             BASELINE MODEL: LOGISTIC REGRESSION RESULTS\n",
      "============================================================\n",
      "\n",
      "1. CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.74      0.79      0.76      1055\n",
      "  Attack (1)       0.72      0.65      0.68       853\n",
      "\n",
      "    accuracy                           0.73      1908\n",
      "   macro avg       0.73      0.72      0.72      1908\n",
      "weighted avg       0.73      0.73      0.73      1908\n",
      "\n",
      "2. AUC-ROC Score: 0.7873\n",
      "\n",
      "3. Training Time: 0.0426 seconds\n",
      "\n",
      "4. CONFUSION MATRIX:\n",
      "True Negatives (TN): 837\n",
      "False Positives (FP): 218\n",
      "False Negatives (FN - CRITICAL ERROR): 300\n",
      "True Positives (TP): 553\n",
      "\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Model Training \n",
    "start_time = time.time()\n",
    "baseline_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=500) \n",
    "\n",
    "baseline_model.fit(X_train_processed, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Prediction \n",
    "y_pred = baseline_model.predict(X_test_processed)\n",
    "\n",
    "# Predict probabilities for AUC-ROC calculation\n",
    "y_proba = baseline_model.predict_proba(X_test_processed)[:, 1] \n",
    "\n",
    "# Evaluation\n",
    "print(\"=\"*60)\n",
    "print(\"             BASELINE MODEL: LOGISTIC REGRESSION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Classification Report (F1, Precision, Recall, Accuracy)\n",
    "print(\"\\n1. CLASSIFICATION REPORT:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal (0)', 'Attack (1)']))\n",
    "\n",
    "# 2. AUC-ROC Score\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"2. AUC-ROC Score: {auc_roc:.4f}\")\n",
    "\n",
    "# 3. Training Time\n",
    "print(f\"\\n3. Training Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# 4. Confusion Matrix (Visualizing Errors)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n4. CONFUSION MATRIX:\")\n",
    "# Visual representation helps to clearly see FN (False Negatives)\n",
    "print(f\"True Negatives (TN): {conf_matrix[0, 0]}\")\n",
    "print(f\"False Positives (FP): {conf_matrix[0, 1]}\")\n",
    "print(f\"False Negatives (FN - CRITICAL ERROR): {conf_matrix[1, 0]}\")\n",
    "print(f\"True Positives (TP): {conf_matrix[1, 1]}\")\n",
    "print(\"\\n----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea40d9-cfd9-4ba3-bc8d-855dec8e0a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
